{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inner Fold Accuracy: 45.04%\n",
      "Inner Fold Accuracy: 54.55%\n",
      "Inner Fold Accuracy: 48.76%\n",
      "Inner Fold Accuracy: 48.35%\n",
      "Inner Fold Accuracy: 54.13%\n",
      "Inner Fold Accuracy: 47.93%\n",
      "Inner Fold Accuracy: 49.79%\n",
      "Inner Fold Accuracy: 46.47%\n",
      "Inner Fold Accuracy: 52.70%\n",
      "Inner Fold Accuracy: 53.53%\n",
      "Outer Fold Mean Inner Accuracy: 50.12%\n",
      "Outer Fold Accuracy: 50.93%\n",
      "Inner Fold Accuracy: 47.52%\n",
      "Inner Fold Accuracy: 44.63%\n",
      "Inner Fold Accuracy: 49.59%\n",
      "Inner Fold Accuracy: 51.65%\n",
      "Inner Fold Accuracy: 45.04%\n",
      "Inner Fold Accuracy: 51.24%\n",
      "Inner Fold Accuracy: 44.81%\n",
      "Inner Fold Accuracy: 51.87%\n",
      "Inner Fold Accuracy: 48.13%\n",
      "Inner Fold Accuracy: 50.21%\n",
      "Outer Fold Mean Inner Accuracy: 48.47%\n",
      "Outer Fold Accuracy: 45.35%\n",
      "Inner Fold Accuracy: 46.28%\n",
      "Inner Fold Accuracy: 52.89%\n",
      "Inner Fold Accuracy: 46.28%\n",
      "Inner Fold Accuracy: 48.35%\n",
      "Inner Fold Accuracy: 50.00%\n",
      "Inner Fold Accuracy: 48.35%\n",
      "Inner Fold Accuracy: 48.13%\n",
      "Inner Fold Accuracy: 51.04%\n",
      "Inner Fold Accuracy: 47.30%\n",
      "Inner Fold Accuracy: 53.11%\n",
      "Outer Fold Mean Inner Accuracy: 49.17%\n",
      "Outer Fold Accuracy: 50.19%\n",
      "Inner Fold Accuracy: 43.39%\n",
      "Inner Fold Accuracy: 51.65%\n",
      "Inner Fold Accuracy: 48.76%\n",
      "Inner Fold Accuracy: 44.63%\n",
      "Inner Fold Accuracy: 47.52%\n",
      "Inner Fold Accuracy: 46.69%\n",
      "Inner Fold Accuracy: 52.28%\n",
      "Inner Fold Accuracy: 46.89%\n",
      "Inner Fold Accuracy: 46.89%\n",
      "Inner Fold Accuracy: 46.06%\n",
      "Outer Fold Mean Inner Accuracy: 47.48%\n",
      "Outer Fold Accuracy: 49.81%\n",
      "Inner Fold Accuracy: 53.31%\n",
      "Inner Fold Accuracy: 45.04%\n",
      "Inner Fold Accuracy: 44.63%\n",
      "Inner Fold Accuracy: 50.00%\n",
      "Inner Fold Accuracy: 49.17%\n",
      "Inner Fold Accuracy: 50.41%\n",
      "Inner Fold Accuracy: 48.13%\n",
      "Inner Fold Accuracy: 48.55%\n",
      "Inner Fold Accuracy: 52.28%\n",
      "Inner Fold Accuracy: 48.96%\n",
      "Outer Fold Mean Inner Accuracy: 49.05%\n",
      "Outer Fold Accuracy: 47.96%\n",
      "Inner Fold Accuracy: 52.48%\n",
      "Inner Fold Accuracy: 52.89%\n",
      "Inner Fold Accuracy: 43.39%\n",
      "Inner Fold Accuracy: 56.20%\n",
      "Inner Fold Accuracy: 55.37%\n",
      "Inner Fold Accuracy: 47.52%\n",
      "Inner Fold Accuracy: 54.96%\n",
      "Inner Fold Accuracy: 48.96%\n",
      "Inner Fold Accuracy: 46.47%\n",
      "Inner Fold Accuracy: 48.13%\n",
      "Outer Fold Mean Inner Accuracy: 50.64%\n",
      "Outer Fold Accuracy: 49.25%\n",
      "Inner Fold Accuracy: 54.13%\n",
      "Inner Fold Accuracy: 47.52%\n",
      "Inner Fold Accuracy: 49.59%\n",
      "Inner Fold Accuracy: 57.85%\n",
      "Inner Fold Accuracy: 52.07%\n",
      "Inner Fold Accuracy: 47.93%\n",
      "Inner Fold Accuracy: 43.80%\n",
      "Inner Fold Accuracy: 49.79%\n",
      "Inner Fold Accuracy: 52.28%\n",
      "Inner Fold Accuracy: 49.38%\n",
      "Outer Fold Mean Inner Accuracy: 50.43%\n",
      "Outer Fold Accuracy: 44.40%\n",
      "Inner Fold Accuracy: 50.00%\n",
      "Inner Fold Accuracy: 49.59%\n",
      "Inner Fold Accuracy: 52.07%\n",
      "Inner Fold Accuracy: 48.35%\n",
      "Inner Fold Accuracy: 53.72%\n",
      "Inner Fold Accuracy: 47.11%\n",
      "Inner Fold Accuracy: 59.09%\n",
      "Inner Fold Accuracy: 48.96%\n",
      "Inner Fold Accuracy: 42.74%\n",
      "Inner Fold Accuracy: 52.28%\n",
      "Outer Fold Mean Inner Accuracy: 50.39%\n",
      "Outer Fold Accuracy: 44.78%\n",
      "Inner Fold Accuracy: 49.17%\n",
      "Inner Fold Accuracy: 43.39%\n",
      "Inner Fold Accuracy: 53.72%\n",
      "Inner Fold Accuracy: 47.52%\n",
      "Inner Fold Accuracy: 54.13%\n",
      "Inner Fold Accuracy: 46.69%\n",
      "Inner Fold Accuracy: 47.52%\n",
      "Inner Fold Accuracy: 53.11%\n",
      "Inner Fold Accuracy: 46.47%\n",
      "Inner Fold Accuracy: 51.87%\n",
      "Outer Fold Mean Inner Accuracy: 49.36%\n",
      "Outer Fold Accuracy: 47.76%\n",
      "Inner Fold Accuracy: 52.48%\n",
      "Inner Fold Accuracy: 54.96%\n",
      "Inner Fold Accuracy: 56.61%\n",
      "Inner Fold Accuracy: 49.59%\n",
      "Inner Fold Accuracy: 45.87%\n",
      "Inner Fold Accuracy: 45.45%\n",
      "Inner Fold Accuracy: 47.52%\n",
      "Inner Fold Accuracy: 47.30%\n",
      "Inner Fold Accuracy: 51.04%\n",
      "Inner Fold Accuracy: 46.47%\n",
      "Outer Fold Mean Inner Accuracy: 49.73%\n",
      "Outer Fold Accuracy: 45.90%\n",
      "Mean Outer Accuracy: 47.63%\n",
      "Best model parameters: OrderedDict({'fc1.weight': tensor([[ 0.0190,  0.0323,  0.0054,  ..., -0.0215,  0.0370,  0.0206],\n",
      "        [-0.0275, -0.0253, -0.0002,  ...,  0.0277, -0.0298, -0.0082],\n",
      "        [ 0.0221, -0.0025,  0.0244,  ..., -0.0024,  0.0189,  0.0286],\n",
      "        ...,\n",
      "        [-0.0386, -0.0372,  0.0103,  ...,  0.0049, -0.0341, -0.0215],\n",
      "        [ 0.0091,  0.0295, -0.0354,  ...,  0.0187,  0.0214,  0.0204],\n",
      "        [-0.0183, -0.0127, -0.0050,  ...,  0.0174, -0.0179,  0.0358]]), 'fc1.bias': tensor([ 1.4300e-02,  2.1220e-02,  1.2324e-02,  1.7011e-02, -3.7162e-02,\n",
      "         1.7579e-02, -3.7519e-02,  1.3989e-03,  1.4451e-02, -2.3655e-02,\n",
      "         3.4173e-03,  3.5245e-02, -3.6160e-02, -3.9189e-02,  3.7331e-02,\n",
      "         3.3612e-02,  2.3488e-02, -3.1487e-02, -1.5436e-02,  7.9948e-03,\n",
      "        -3.2299e-03,  3.9534e-02, -1.1510e-02,  4.1260e-02, -3.6787e-02,\n",
      "         1.8575e-02,  3.1365e-02,  3.0609e-02,  1.0992e-02, -3.3158e-02,\n",
      "        -8.3444e-03,  1.2961e-02,  1.6914e-02,  2.4042e-02, -4.1010e-02,\n",
      "         3.2951e-02,  3.7800e-02,  3.8436e-02, -2.6456e-03,  3.2995e-02,\n",
      "        -5.9002e-03, -2.1952e-03,  1.7397e-02,  2.3934e-02, -2.8452e-03,\n",
      "        -2.0054e-02, -1.0246e-02, -3.9310e-02, -2.5904e-02,  3.0201e-02,\n",
      "         3.0231e-03,  2.0567e-02,  3.3600e-02,  1.5072e-02,  2.8142e-02,\n",
      "         3.6258e-02, -2.2035e-02, -3.1410e-02,  3.9794e-02, -8.0997e-03,\n",
      "        -1.2815e-02, -3.3613e-02, -2.4918e-02, -1.4413e-03, -1.6719e-02,\n",
      "        -1.9695e-02, -2.1258e-02,  2.2501e-03, -3.6700e-03, -1.0954e-02,\n",
      "        -3.8607e-02,  1.7786e-02, -1.5250e-02,  1.0966e-02,  1.8948e-02,\n",
      "        -5.4916e-03,  1.7707e-02, -2.3601e-02, -6.4908e-04, -1.7900e-02,\n",
      "         2.5675e-02, -1.2628e-02, -2.5372e-02, -2.0031e-02,  1.1228e-02,\n",
      "         3.4507e-02, -9.3566e-03,  1.5917e-02,  3.6496e-02, -2.1642e-02,\n",
      "        -3.4018e-02, -3.1818e-02, -1.3452e-02, -3.7135e-02,  1.4156e-02,\n",
      "         3.0980e-02,  6.8625e-04,  3.3714e-02, -1.9374e-02, -1.0066e-02,\n",
      "        -6.8319e-05,  6.5794e-03,  2.1152e-02,  8.3370e-03, -2.9276e-02,\n",
      "         3.9325e-02, -1.5451e-03, -3.3477e-02,  1.9354e-02, -3.9776e-03,\n",
      "        -2.4518e-02,  4.0287e-02,  2.4997e-02, -7.4120e-03,  1.8520e-02,\n",
      "        -2.1287e-02,  5.4456e-03,  3.1842e-02, -4.0672e-02, -3.5776e-02,\n",
      "        -3.7294e-02,  2.6206e-02,  3.6996e-03,  2.0196e-02,  4.1533e-02,\n",
      "        -2.3620e-02, -2.1360e-03,  3.5625e-02]), 'fc2.weight': tensor([[ 7.5653e-02,  6.4034e-02, -6.2607e-02, -2.4624e-02, -3.7088e-02,\n",
      "          3.1723e-02, -8.7485e-02, -5.3946e-02, -6.9703e-02,  3.9965e-02,\n",
      "         -1.8114e-02,  7.9814e-02, -8.3356e-02,  2.2523e-02, -1.0223e-01,\n",
      "          4.8322e-03,  1.4362e-02,  8.3496e-02, -8.9761e-05,  2.3707e-02,\n",
      "          9.1539e-03, -5.0583e-02,  5.1356e-02, -5.8207e-02,  7.4460e-02,\n",
      "         -1.2086e-02,  6.0001e-02,  5.2990e-02, -6.8957e-02, -1.1221e-02,\n",
      "          7.4344e-02, -1.1262e-02,  7.0017e-02, -6.7577e-02,  4.1313e-02,\n",
      "         -6.7398e-02,  7.0313e-03,  6.8409e-03, -8.8413e-02,  8.9034e-02,\n",
      "          4.5716e-02, -6.1524e-02,  1.3600e-02,  6.3887e-02, -4.5287e-02,\n",
      "         -1.0373e-01,  4.4516e-02, -5.2575e-02, -8.2290e-03,  5.6861e-02,\n",
      "          4.8237e-02,  6.1047e-02,  6.9624e-02,  1.0290e-01, -2.8010e-02,\n",
      "         -6.4956e-02, -6.0471e-02, -8.9618e-02,  4.5290e-02,  5.6651e-02,\n",
      "         -3.0858e-02,  6.5340e-02, -9.5083e-02,  9.7835e-02,  5.1288e-02,\n",
      "          1.7702e-02, -2.8726e-02, -6.8964e-02, -3.1097e-02, -2.3571e-02,\n",
      "         -8.3373e-02, -3.8547e-03, -3.8917e-02,  8.9964e-02,  1.1148e-02,\n",
      "         -8.4195e-02,  8.8088e-02, -4.3843e-02, -6.8587e-02, -2.1852e-03,\n",
      "          7.4234e-02, -4.9178e-02, -1.6865e-03, -3.9458e-02,  3.8501e-02,\n",
      "          4.3377e-02, -9.6055e-02,  3.5123e-02, -7.0155e-02, -1.3730e-03,\n",
      "          1.0744e-02, -5.3791e-02,  4.0079e-02,  7.3607e-02,  7.8774e-02,\n",
      "          1.1563e-03,  4.3604e-02, -6.2173e-02,  2.8002e-02, -7.7650e-02,\n",
      "          8.8067e-02,  2.8555e-02,  5.9686e-02,  4.9128e-02, -2.9730e-02,\n",
      "         -7.3360e-02, -5.6091e-02,  6.4546e-02, -3.7036e-02,  2.5900e-02,\n",
      "         -5.3681e-02,  3.6307e-02, -6.3361e-02,  7.0339e-03,  6.8833e-02,\n",
      "          5.1974e-02, -4.6350e-02,  1.7139e-02, -7.0405e-02,  2.9982e-02,\n",
      "         -6.2972e-02, -1.4283e-02, -6.8901e-02, -1.0043e-01, -9.0440e-02,\n",
      "          2.8271e-02, -4.8906e-02,  1.4281e-02],\n",
      "        [-1.4821e-02, -1.0694e-02,  7.8323e-02,  3.8149e-02, -8.8709e-02,\n",
      "          2.0095e-02,  1.6420e-02, -1.4793e-02,  4.5171e-02, -4.3756e-03,\n",
      "         -4.2241e-02, -3.8071e-02, -1.2997e-02,  5.3919e-02,  5.5004e-02,\n",
      "          1.1214e-02,  7.3218e-02,  5.8444e-02,  1.7602e-02,  9.2798e-02,\n",
      "         -4.0455e-02,  4.4631e-02, -7.9876e-03, -6.5298e-02, -5.6032e-02,\n",
      "          3.3817e-02, -3.8558e-03,  2.0123e-02, -3.5462e-02, -4.6857e-03,\n",
      "         -1.1861e-02, -2.2661e-03, -1.1289e-01, -6.3793e-02,  7.0926e-02,\n",
      "          7.5893e-02,  9.6840e-02, -6.5972e-02, -8.0396e-03,  5.4279e-03,\n",
      "          8.1416e-02,  4.7981e-02, -3.3319e-02,  9.1157e-02,  5.2693e-03,\n",
      "          2.7747e-02,  2.3993e-02,  7.4823e-03, -3.0976e-02, -8.5084e-02,\n",
      "          1.9861e-02,  4.0265e-02, -1.9123e-02,  7.7121e-03, -4.3905e-02,\n",
      "         -3.8045e-02, -5.4151e-02,  6.5348e-02,  3.0119e-02, -5.5212e-02,\n",
      "         -1.7183e-02, -5.1881e-02,  1.0646e-01, -1.0550e-01, -3.1466e-04,\n",
      "         -7.9409e-02,  1.6780e-02, -3.0781e-02, -5.2976e-02, -3.3357e-02,\n",
      "         -1.8700e-03, -3.7562e-02, -4.1153e-02,  8.3449e-03,  5.3069e-02,\n",
      "          6.1098e-02,  8.0492e-03, -7.3205e-02,  2.6258e-02, -8.6551e-02,\n",
      "         -1.3524e-02, -1.7072e-02, -7.5249e-02, -5.5925e-02, -9.8374e-02,\n",
      "         -7.8163e-03, -4.4455e-02,  5.1416e-02, -5.3946e-02,  9.1491e-02,\n",
      "         -8.8709e-02,  4.8962e-02,  1.2008e-02, -9.3227e-02, -7.3887e-02,\n",
      "          4.7748e-02, -8.5508e-02,  7.3545e-02,  3.6554e-02,  6.9078e-02,\n",
      "          3.0432e-02,  7.6770e-02, -9.4296e-02,  4.7356e-03, -6.8194e-03,\n",
      "          3.8711e-02,  3.9868e-03, -7.7359e-02, -1.9189e-03, -5.8899e-02,\n",
      "         -6.4871e-02,  1.4220e-02,  8.3661e-02, -4.9805e-02, -5.0990e-02,\n",
      "         -8.5652e-02,  5.8979e-02, -1.9827e-02, -7.9165e-03, -3.8379e-02,\n",
      "         -2.5815e-02,  4.2525e-02,  6.1761e-02,  8.9574e-02,  9.7235e-02,\n",
      "          3.3195e-02, -1.9926e-02, -1.1139e-01]]), 'fc2.bias': tensor([-0.0874, -0.0302])})\n",
      "Holdout Set Accuracy: 50.20%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset, TensorDataset\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('pseudodata_prÃ¦operation.csv')\n",
    "\n",
    "# # #make pd to np\n",
    "X = data.to_numpy()\n",
    "y = np.random.choice([0, 1], size=len(data))\n",
    "\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "# Create a dataset\n",
    "dataset = TensorDataset(X_tensor, y_tensor)\n",
    "\n",
    "# Split data into holdout set and remaining set\n",
    "indices = np.arange(len(dataset))\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(indices)\n",
    "holdout_indices = indices[:500]\n",
    "remaining_indices = indices[500:]\n",
    "\n",
    "holdout_set = Subset(dataset, holdout_indices)\n",
    "remaining_set = Subset(dataset, remaining_indices)\n",
    "\n",
    "# Define the ANN model with L2 regularization\n",
    "class ANNModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(ANNModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "input_dim = 575\n",
    "hidden_dim = 128\n",
    "output_dim = 2\n",
    "\n",
    "# Function to train and evaluate the model with L2 regularization\n",
    "def train_and_evaluate_model(train_loader, val_loader, input_dim, hidden_dim, output_dim, num_epochs=10, lr=0.01, weight_decay=1e-5):\n",
    "    model = ANNModel(input_dim, hidden_dim, output_dim)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for images, labels in train_loader:\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    accuracy = correct / total\n",
    "    return accuracy, model\n",
    "\n",
    "# Outer 10-Fold Cross-Validation\n",
    "outer_kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "outer_accuracies = []\n",
    "best_model_params = None\n",
    "best_outer_accuracy = 0\n",
    "\n",
    "for outer_train_index, outer_test_index in outer_kf.split(remaining_indices):\n",
    "    outer_train_subset = Subset(remaining_set, outer_train_index)\n",
    "    outer_test_subset = Subset(remaining_set, outer_test_index)\n",
    "    \n",
    "    # Inner 10-Fold Cross-Validation\n",
    "    inner_kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    inner_accuracies = []\n",
    "\n",
    "    for inner_train_index, inner_val_index in inner_kf.split(outer_train_index):\n",
    "        inner_train_indices = np.array(outer_train_index)[inner_train_index]\n",
    "        inner_val_indices = np.array(outer_train_index)[inner_val_index]\n",
    "        \n",
    "        inner_train_subset = Subset(remaining_set, inner_train_indices)\n",
    "        inner_val_subset = Subset(remaining_set, inner_val_indices)\n",
    "        \n",
    "        train_loader = DataLoader(inner_train_subset, batch_size=64, shuffle=True)\n",
    "        val_loader = DataLoader(inner_val_subset, batch_size=64, shuffle=False)\n",
    "        \n",
    "        accuracy, model = train_and_evaluate_model(train_loader, val_loader, input_dim, hidden_dim, output_dim)\n",
    "        inner_accuracies.append(accuracy)\n",
    "        print(f'Inner Fold Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "    mean_inner_accuracy = np.mean(inner_accuracies)\n",
    "    print(f'Outer Fold Mean Inner Accuracy: {mean_inner_accuracy * 100:.2f}%')\n",
    "\n",
    "    train_loader = DataLoader(outer_train_subset, batch_size=64, shuffle=True)\n",
    "    test_loader = DataLoader(outer_test_subset, batch_size=64, shuffle=False)\n",
    "    \n",
    "    outer_accuracy, outer_model = train_and_evaluate_model(train_loader, test_loader, input_dim, hidden_dim, output_dim)\n",
    "    outer_accuracies.append(outer_accuracy)\n",
    "    print(f'Outer Fold Accuracy: {outer_accuracy * 100:.2f}%')\n",
    "\n",
    "    if outer_accuracy > best_outer_accuracy:\n",
    "        best_outer_accuracy = outer_accuracy\n",
    "        best_model_params = outer_model.state_dict()\n",
    "\n",
    "print(f'Mean Outer Accuracy: {np.mean(outer_accuracies) * 100:.2f}%')\n",
    "print('Best model parameters:', best_model_params)\n",
    "\n",
    "# Evaluate the final model on the holdout set\n",
    "final_model = ANNModel(input_dim, hidden_dim, output_dim)\n",
    "final_model.load_state_dict(best_model_params)\n",
    "train_loader = DataLoader(remaining_set, batch_size=64, shuffle=True)\n",
    "holdout_loader = DataLoader(holdout_set, batch_size=64, shuffle=False)\n",
    "\n",
    "# Train the final model on the remaining set and evaluate on the holdout set\n",
    "final_model_accuracy, _ = train_and_evaluate_model(train_loader, holdout_loader, input_dim, hidden_dim, output_dim)\n",
    "print(f'Holdout Set Accuracy: {final_model_accuracy * 100:.2f}%')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "activelearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

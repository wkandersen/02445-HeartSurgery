{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "data = pd.read_csv('pseudodata_præoperation.csv')\n",
    "y = np.random.choice([0,1],size = len(data))\n",
    "\n",
    "X = data.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from xgboost import XGBClassifier\n",
    "from skopt.space import Real, Integer\n",
    "\n",
    "# # Generate synthetic data\n",
    "# X, y = make_classification(n_samples=6000, n_features=20, random_state=42)\n",
    "\n",
    "# Split data into training and hold-out sets\n",
    "X_train, X_holdout, y_train, y_holdout = train_test_split(X, y, test_size=1/6, random_state=42)\n",
    "\n",
    "# Calculate scale_pos_weight based on training data\n",
    "num_negative = np.sum(y_train == 0)\n",
    "num_positive = np.sum(y_train == 1)\n",
    "scale_pos_weight = num_negative / num_positive\n",
    "\n",
    "# Initialize XGBoost classifier\n",
    "model = XGBClassifier()\n",
    "\n",
    "# Define the hyperparameter space\n",
    "param_space = {\n",
    "    'n_estimators': Integer(10, 5000),\n",
    "    'max_depth': Integer(1, 10),\n",
    "    'learning_rate': Real(0.001, 0.01, prior='log-uniform'),\n",
    "    'subsample': Real(0.6, 1.0),\n",
    "    'colsample_bytree': Real(0.6, 1.0),\n",
    "    'gamma': Real(0, 5),\n",
    "    'scale_pos_weight': Real(scale_pos_weight*0.25, scale_pos_weight*2)\n",
    "}\n",
    "\n",
    "# Define the scoring metrics\n",
    "scoring = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
    "\n",
    "# Initialize BayesSearchCV\n",
    "opt = BayesSearchCV(\n",
    "    estimator=model,\n",
    "    search_spaces=param_space,\n",
    "    scoring=scoring,\n",
    "    n_iter=50,  # Number of iterations for Bayesian optimization\n",
    "    cv=5,  # Number of cross-validation folds\n",
    "    n_jobs=-1,\n",
    "    return_train_score=True,\n",
    "    refit='roc_auc',  # Refit the best model on the entire training set using ROC AUC\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Perform Bayesian optimization\n",
    "opt.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on hold-out set\n",
    "y_pred_holdout = opt.predict(X_holdout)\n",
    "print(\"Hold-Out Set Metrics:\")\n",
    "for metric in scoring:\n",
    "    if metric in ['accuracy', 'precision', 'recall', 'f1']:\n",
    "        score = globals()[f\"{metric}_score\"](y_holdout, y_pred_holdout)\n",
    "    elif metric == 'roc_auc':\n",
    "        score = roc_auc_score(y_holdout, opt.predict_proba(X_holdout)[:, 1])\n",
    "    print(f\"{metric.capitalize()}: {score}\")\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best parameters:\", opt.best_params_)\n",
    "print(\"Best ROC AUC:\", opt.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Real(low=0.25, high=2.0, prior='uniform', transform='identity')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Real(scale_pos_weight*0.25, scale_pos_weight*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n",
      "Best parameters found: {'learning_rate': 0.3, 'max_depth': 5, 'n_estimators': 1000, 'scale_pos_weight': 1327}\n",
      "Best cross-validation accuracy: 0.50113\n",
      "Final Model Accuracy on Holdout Set: 50.47%\n",
      "Holdout Set Precision: 48.66%\n",
      "Holdout Set Recall: 79.37%\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "\n",
    "# Load and preprocess data\n",
    "# data = pd.read_csv('x_matricer/x_matrix_pre_4729.csv', compression='gzip').sort_values(by='IDno', ignore_index=True).drop(columns='IDno')\n",
    "# y_pred = pd.read_csv('y_pred_4729.csv').sort_values(by='IDno', ignore_index=True).drop(columns='IDno')\n",
    "# X = data.to_numpy()\n",
    "# y = y_pred.to_numpy().flatten()\n",
    "\n",
    "# # Standardize the data\n",
    "# X = StandardScaler().fit_transform(X)\n",
    "\n",
    "data = pd.read_csv('pseudodata_præoperation.csv')\n",
    "y = np.random.choice([0,1],size = len(data))\n",
    "\n",
    "X = data.to_numpy()\n",
    "\n",
    "# Split data into holdout set and remaining set\n",
    "X_train, X_holdout, y_train, y_holdout = train_test_split(X, y, test_size=1/6, random_state=42)\n",
    "\n",
    "# Create a DMatrix for XGBoost\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dholdout = xgb.DMatrix(X_holdout, label=y_holdout)\n",
    "\n",
    "scale_pos_weight = num_negative / num_positive\n",
    "\n",
    "# Define a simple parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.0001, 0.001, 0.01, 0.3],\n",
    "    'n_estimators': [10, 50, 100, 500, 1000, 5000],\n",
    "    'scale_pos_weight': [0.1*num_negative,num_negative,num_negative*1.5,num_negative*2]  # Adjust for class imbalance\n",
    "}\n",
    "\n",
    "# Initialize a XGBoost model\n",
    "xgb_model = xgb.XGBClassifier(objective='binary:logistic', use_label_encoder=False)\n",
    "\n",
    "scoring = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
    "\n",
    "# Perform Grid Search with Cross-Validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, scoring='f1', cv=cv, verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters found\n",
    "print(f'Best parameters found: {grid_search.best_params_}')\n",
    "print(f'Best cross-validation accuracy: {grid_search.best_score_:.5f}')\n",
    "\n",
    "# Train the final model with the best parameters\n",
    "best_model = grid_search.best_estimator_\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the final model on the holdout set\n",
    "y_holdout_pred = best_model.predict(X_holdout)\n",
    "accuracy = accuracy_score(y_holdout, y_holdout_pred)\n",
    "precision = precision_score(y_holdout, y_holdout_pred)\n",
    "recall = recall_score(y_holdout, y_holdout_pred)\n",
    "\n",
    "print(f'Final Model Accuracy on Holdout Set: {accuracy * 100:.2f}%')\n",
    "print(f'Holdout Set Precision: {precision * 100:.2f}%')\n",
    "print(f'Holdout Set Recall: {recall * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prøv den her\n",
    "Start med færre parametre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "\n",
    "\n",
    "# Load and preprocess data\n",
    "# data = pd.read_csv('x_matricer/x_matrix_pre_4729.csv', compression='gzip').sort_values(by='IDno', ignore_index=True).drop(columns='IDno')\n",
    "# y_pred = pd.read_csv('y_pred_4729.csv').sort_values(by='IDno', ignore_index=True).drop(columns='IDno')\n",
    "# X = data.to_numpy()\n",
    "# y = y_pred.to_numpy().flatten()\n",
    "\n",
    "# # Standardize the data\n",
    "# X = StandardScaler().fit_transform(X)\n",
    "\n",
    "data1 = pd.read_csv('pseudodata_præoperation.csv')\n",
    "data2 = pd.read_csv('pseudodata_præoperation.csv')\n",
    "data3 = pd.read_csv('pseudodata_præoperation.csv')\n",
    "data4 = pd.read_csv('pseudodata_præoperation.csv')\n",
    "data5 = pd.read_csv('pseudodata_præoperation.csv')\n",
    "data6 = pd.read_csv('pseudodata_præoperation.csv')\n",
    "\n",
    "base = data1\n",
    "phase1 = pd.concat([data1, data2], axis = 1)\n",
    "phase2 = pd.concat([data1, data2, data3], axis = 1)\n",
    "phase3 = pd.concat([data1, data2, data3, data4], axis = 1)\n",
    "phase4 = pd.concat([data1, data2, data3, data4, data5], axis = 1)\n",
    "phase5 = pd.concat([data1, data2, data3, data4, data5, data6], axis = 1)\n",
    "y_pred = \n",
    "data_list = [base, phase1, phase2, phase3, phase4, phase5]\n",
    "\n",
    "preds_log = []\n",
    "models_log = []\n",
    "holdout_log = []\n",
    "true_log = []\n",
    "\n",
    "for i in range(len(data_list)):\n",
    "    print(i)\n",
    "    data = data_list[i]\n",
    "\n",
    "    y = np.random.choice([0,1],size = len(data))\n",
    "\n",
    "    X = data.to_numpy()\n",
    "\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "\n",
    "    # Split data into holdout set and remaining set\n",
    "    X_train, X_holdout, y_train, y_holdout = train_test_split(X,y, test_size=500, random_state=42, stratify=y)\n",
    "\n",
    "    holdout_set = Subset(dataset, holdout_indices)\n",
    "    remaining_set = Subset(dataset, train_indices)\n",
    "\n",
    "    num_negative = np.sum(y == 0)\n",
    "    num_positive = np.sum(y == 1)\n",
    "    scale_pos_weight = num_negative / num_positive\n",
    "\n",
    "    # Create a DMatrix for XGBoost\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dholdout = xgb.DMatrix(X_holdout, label=y_holdout)\n",
    "\n",
    "    # Define a simple parameter grid for hyperparameter tuning\n",
    "    param_grid = {\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'learning_rate': [0.0001, 0.001, 0.01, 0.3],\n",
    "        'n_estimators': [10, 50, 100, 500, 1000, 5000],\n",
    "        'scale_pos_weight': [0.1*num_negative,num_negative,num_negative*1.5,num_negative*2],  # Adjust for class imbalance, \n",
    "    }\n",
    "\n",
    "    # Initialize a XGBoost model\n",
    "    xgb_model = xgb.XGBClassifier(objective='binary:logistic', use_label_encoder=False, early_stopping_rounds = 10)\n",
    "\n",
    "    scoring = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
    "\n",
    "    # Perform Grid Search with Cross-Validation\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, scoring='roc_auc', cv=cv, verbose=1, n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Print the best parameters found\n",
    "    print(f'Best parameters found: {grid_search.best_params_}')\n",
    "    print(f'Best cross-validation accuracy: {grid_search.best_score_:.5f}')\n",
    "\n",
    "    # Train the final model with the best parameters\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate the final model on the holdout set\n",
    "    y_holdout_pred = best_model.predict(X_holdout)\n",
    "    accuracy = accuracy_score(y_holdout, y_holdout_pred)\n",
    "    precision = precision_score(y_holdout, y_holdout_pred)\n",
    "    recall = recall_score(y_holdout, y_holdout_pred)\n",
    "    f1 = f1_score(y_holdout, y_holdout_pred)\n",
    "\n",
    "    models_log.append(best_model)\n",
    "    #holdout_log.append(holdout_loader)\n",
    "    true_log.append(y_holdout)\n",
    "    preds_log.append(y_holdout_pred)\n",
    "\n",
    "    print(f'Final Model Accuracy on Holdout Set: {accuracy * 100:.2f}%')\n",
    "    print(f'Holdout Set Precision: {precision * 100:.2f}%')\n",
    "    print(f'Holdout Set Recall: {recall * 100:.2f}%')\n",
    "    print(f'Holdout Set F1 Score: {f1 * 100:.2f}%')\n",
    "\n",
    "    with open('XGB_output.txt', 'a') as file:\n",
    "        print(f\"Phase {i + 1}\", file=file)\n",
    "        print(f'Best parameters: {grid_search.best_params_}', file=file)\n",
    "        print(f'Final Model F1 Score on Holdout Set: {f1:.4f}', file=file)\n",
    "        print(f'Holdout Set Accuracy: {accuracy * 100:.2f}%', file=file)\n",
    "        print(f'Holdout Set Precision: {precision * 100:.2f}%', file=file)\n",
    "        print(f'Holdout Set Recall: {recall * 100:.2f}%', file=file)\n",
    "        print('\\n', file=file)\n",
    "        print('Output written to output.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, confusion_matrix\n",
    "\n",
    "# Split data into holdout set and remaining set\n",
    "train_indices, holdout_indices = train_test_split(np.arange(len(X)), test_size=500, random_state=42, stratify=y)\n",
    "X_train, X_holdout = X[train_indices], X[holdout_indices]\n",
    "y_train, y_holdout = y[train_indices], y[holdout_indices]\n",
    "\n",
    "# Check class distribution\n",
    "print(\"Class distribution in training set:\", np.bincount(y_train.astype(int)))\n",
    "print(\"Class distribution in holdout set:\", np.bincount(y_holdout.astype(int)))\n",
    "\n",
    "# Create a DMatrix for XGBoost\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dholdout = xgb.DMatrix(X_holdout, label=y_holdout)\n",
    "\n",
    "# Define a simple parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.3],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'scale_pos_weight': [np.sum(y_train == 0) / np.sum(y_train == 1)]  # Adjust for class imbalance\n",
    "}\n",
    "\n",
    "# Initialize a XGBoost model\n",
    "xgb_model = xgb.XGBClassifier(objective='binary:logistic', use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "# Perform Grid Search with Cross-Validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, scoring='accuracy', cv=cv, verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters found\n",
    "print(f'Best parameters found: {grid_search.best_params_}')\n",
    "print(f'Best cross-validation accuracy: {grid_search.best_score_:.5f}')\n",
    "\n",
    "# Train the final model with the best parameters\n",
    "best_model = grid_search.best_estimator_\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the final model on the holdout set\n",
    "y_holdout_pred = best_model.predict(X_holdout)\n",
    "accuracy = accuracy_score(y_holdout, y_holdout_pred)\n",
    "precision = precision_score(y_holdout, y_holdout_pred)\n",
    "recall = recall_score(y_holdout, y_holdout_pred)\n",
    "\n",
    "print(f'Final Model Accuracy on Holdout Set: {accuracy * 100:.2f}%')\n",
    "print(f'Holdout Set Precision: {precision * 100:.2f}%')\n",
    "print(f'Holdout Set Recall: {recall * 100:.2f}%')\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_holdout, y_holdout_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, confusion_matrix, roc_auc_score\n",
    "\n",
    "\n",
    "# Split data into holdout set and remaining set\n",
    "train_indices, holdout_indices = train_test_split(np.arange(len(X)), test_size=500, random_state=42, stratify=y)\n",
    "X_train, X_holdout = X[train_indices], X[holdout_indices]\n",
    "y_train, y_holdout = y[train_indices], y[holdout_indices]\n",
    "\n",
    "# Check class distribution\n",
    "print(\"Class distribution in training set:\", np.bincount(y_train.astype(int)))\n",
    "print(\"Class distribution in holdout set:\", np.bincount(y_holdout.astype(int)))\n",
    "\n",
    "# Initialize a simple XGBoost model\n",
    "xgb_model = xgb.XGBClassifier(objective='binary:logistic', use_label_encoder=False, eval_metric='logloss', scale_pos_weight=np.sum(y_train == 0) / np.sum(y_train == 1))\n",
    "\n",
    "# Perform Cross-Validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(xgb_model, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "print(f'Cross-validation scores: {cv_scores}')\n",
    "print(f'Mean cross-validation accuracy: {cv_scores.mean():.5f}')\n",
    "\n",
    "# Train the final model on the entire training set\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the final model on the holdout set\n",
    "y_holdout_pred = xgb_model.predict(X_holdout)\n",
    "accuracy = accuracy_score(y_holdout, y_holdout_pred)\n",
    "precision = precision_score(y_holdout, y_holdout_pred)\n",
    "recall = recall_score(y_holdout, y_holdout_pred)\n",
    "roc_auc = roc_auc_score(y_holdout, y_holdout_pred)\n",
    "\n",
    "print(f'Final Model Accuracy on Holdout Set: {accuracy * 100:.2f}%')\n",
    "print(f'Holdout Set Precision: {precision * 100:.2f}%')\n",
    "print(f'Holdout Set Recall: {recall * 100:.2f}%')\n",
    "print(f'Holdout Set ROC AUC: {roc_auc * 100:.2f}%')\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_holdout, y_holdout_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

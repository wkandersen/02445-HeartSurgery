{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate xgboost algorithm for classification\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "# define dataset\n",
    "data = pd.read_csv('x_matricer/x_matrix_pre_4729.csv', compression='gzip').sort_values(by='IDno',ignore_index=True).drop(columns='IDno')\n",
    "y_pred = pd.read_csv('y_pred_4729.csv').sort_values(by='IDno',ignore_index=True).drop(columns='IDno')\n",
    "\n",
    "# Convert to numpy array and generate synthetic labels for demonstration\n",
    "X = data.to_numpy()\n",
    "y = y_pred.to_numpy()\n",
    "# define the model\n",
    "model = XGBClassifier()\n",
    "# evaluate the model\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(model, X, y, scoring = 'accuracy', cv=cv, n_jobs=-1)\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# test regression dataset\n",
    "from sklearn.datasets import make_regression\n",
    "# define dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=20, n_informative=15, noise=0.1, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "model = XGBRegressor()\n",
    "# evaluate the model\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(model, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1, error_score='raise')\n",
    "# report performance\n",
    "print('MAE: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore xgboost number of trees effect on performance\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "from matplotlib import pyplot\n",
    "\n",
    "\n",
    "\n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "\tmodels = dict()\n",
    "\ttrees = [10, 50, 100, 500, 1000, 5000]\n",
    "\tfor n in trees:\n",
    "\t\tmodels[str(n)] = XGBClassifier(n_estimators=n)\n",
    "\treturn models\n",
    "\n",
    "# evaluate a give model using cross-validation\n",
    "def evaluate_model(model):\n",
    "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\tscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\treturn scores\n",
    "\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "\tscores = evaluate_model(model)\n",
    "\tresults.append(scores)\n",
    "\tnames.append(name)\n",
    "\tprint('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
    "# plot model performance for comparison\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore xgboost tree depth effect on performance\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "from matplotlib import pyplot\n",
    "\n",
    "\n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "\tmodels = dict()\n",
    "\tfor i in range(1,11):\n",
    "\t\tmodels[str(i)] = XGBClassifier(max_depth=i)\n",
    "\treturn models\n",
    "\n",
    "# evaluate a give model using cross-validation\n",
    "def evaluate_model(model):\n",
    "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\tscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\treturn scores\n",
    "\n",
    "\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "\tscores = evaluate_model(model)\n",
    "\tresults.append(scores)\n",
    "\tnames.append(name)\n",
    "\tprint('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
    "# plot model performance for comparison\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore xgboost learning rate effect on performance\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# get the dataset\n",
    "def get_dataset():\n",
    "\tX, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=7)\n",
    "\treturn X, y\n",
    "\n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "\tmodels = dict()\n",
    "\trates = [0.00001, 0.001, 0.01, 0.1, 1.0]\n",
    "\tfor r in rates:\n",
    "\t\tkey = '%.4f' % r\n",
    "\t\tmodels[key] = XGBClassifier(eta=r)\n",
    "\treturn models\n",
    "\n",
    "# evaluate a give model using cross-validation\n",
    "def evaluate_model(model):\n",
    "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\tscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\treturn scores\n",
    "\n",
    "\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "\tscores = evaluate_model(model)\n",
    "\tresults.append(scores)\n",
    "\tnames.append(name)\n",
    "\tprint('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
    "# plot model performance for comparison\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore xgboost subsample ratio effect on performance\n",
    "from numpy import arange\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# get the dataset\n",
    "def get_dataset():\n",
    "\tX, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=7)\n",
    "\treturn X, y\n",
    "\n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "\tmodels = dict()\n",
    "\tfor i in arange(0.1, 1.1, 0.1):\n",
    "\t\tkey = '%.1f' % i\n",
    "\t\tmodels[key] = XGBClassifier(subsample=i)\n",
    "\treturn models\n",
    "\n",
    "# evaluate a give model using cross-validation\n",
    "def evaluate_model(model):\n",
    "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\tscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\treturn scores\n",
    "\n",
    "\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "\tprint(name)\n",
    "\tscores = evaluate_model(model)\n",
    "\tresults.append(scores)\n",
    "\tnames.append(name)\n",
    "\tprint('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
    "# plot model performance for comparison\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "\n",
    "# Load and preprocess data\n",
    "data = pd.read_csv('x_matricer/x_matrix_pre_4729.csv', compression='gzip').sort_values(by='IDno', ignore_index=True).drop(columns='IDno')\n",
    "y_pred = pd.read_csv('y_pred_4729.csv').sort_values(by='IDno', ignore_index=True).drop(columns='IDno')\n",
    "X = data.to_numpy()\n",
    "y = y_pred.to_numpy().flatten()\n",
    "\n",
    "# Standardize the data\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "# Split data into holdout set and remaining set\n",
    "train_indices, holdout_indices = train_test_split(np.arange(len(X)), test_size=500, random_state=42, stratify=y)\n",
    "X_train, X_holdout = X[train_indices], X[holdout_indices]\n",
    "y_train, y_holdout = y[train_indices], y[holdout_indices]\n",
    "\n",
    "# Create a DMatrix for XGBoost\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dholdout = xgb.DMatrix(X_holdout, label=y_holdout)\n",
    "\n",
    "# Define a simple parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.3],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'scale_pos_weight': [1/0.02]  # Adjust for class imbalance\n",
    "}\n",
    "\n",
    "# Initialize a XGBoost model\n",
    "xgb_model = xgb.XGBClassifier(objective='binary:logistic', use_label_encoder=False)\n",
    "\n",
    "# Perform Grid Search with Cross-Validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, scoring='accuracy', cv=cv, verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters found\n",
    "print(f'Best parameters found: {grid_search.best_params_}')\n",
    "print(f'Best cross-validation accuracy: {grid_search.best_score_:.5f}')\n",
    "\n",
    "# Train the final model with the best parameters\n",
    "best_model = grid_search.best_estimator_\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the final model on the holdout set\n",
    "y_holdout_pred = best_model.predict(X_holdout)\n",
    "accuracy = accuracy_score(y_holdout, y_holdout_pred)\n",
    "precision = precision_score(y_holdout, y_holdout_pred)\n",
    "recall = recall_score(y_holdout, y_holdout_pred)\n",
    "\n",
    "print(f'Final Model Accuracy on Holdout Set: {accuracy * 100:.2f}%')\n",
    "print(f'Holdout Set Precision: {precision * 100:.2f}%')\n",
    "print(f'Holdout Set Recall: {recall * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, confusion_matrix\n",
    "\n",
    "# Split data into holdout set and remaining set\n",
    "train_indices, holdout_indices = train_test_split(np.arange(len(X)), test_size=500, random_state=42, stratify=y)\n",
    "X_train, X_holdout = X[train_indices], X[holdout_indices]\n",
    "y_train, y_holdout = y[train_indices], y[holdout_indices]\n",
    "\n",
    "# Check class distribution\n",
    "print(\"Class distribution in training set:\", np.bincount(y_train.astype(int)))\n",
    "print(\"Class distribution in holdout set:\", np.bincount(y_holdout.astype(int)))\n",
    "\n",
    "# Create a DMatrix for XGBoost\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dholdout = xgb.DMatrix(X_holdout, label=y_holdout)\n",
    "\n",
    "# Define a simple parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.3],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'scale_pos_weight': [np.sum(y_train == 0) / np.sum(y_train == 1)]  # Adjust for class imbalance\n",
    "}\n",
    "\n",
    "# Initialize a XGBoost model\n",
    "xgb_model = xgb.XGBClassifier(objective='binary:logistic', use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "# Perform Grid Search with Cross-Validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, scoring='accuracy', cv=cv, verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters found\n",
    "print(f'Best parameters found: {grid_search.best_params_}')\n",
    "print(f'Best cross-validation accuracy: {grid_search.best_score_:.5f}')\n",
    "\n",
    "# Train the final model with the best parameters\n",
    "best_model = grid_search.best_estimator_\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the final model on the holdout set\n",
    "y_holdout_pred = best_model.predict(X_holdout)\n",
    "accuracy = accuracy_score(y_holdout, y_holdout_pred)\n",
    "precision = precision_score(y_holdout, y_holdout_pred)\n",
    "recall = recall_score(y_holdout, y_holdout_pred)\n",
    "\n",
    "print(f'Final Model Accuracy on Holdout Set: {accuracy * 100:.2f}%')\n",
    "print(f'Holdout Set Precision: {precision * 100:.2f}%')\n",
    "print(f'Holdout Set Recall: {recall * 100:.2f}%')\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_holdout, y_holdout_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, confusion_matrix, roc_auc_score\n",
    "\n",
    "\n",
    "# Split data into holdout set and remaining set\n",
    "train_indices, holdout_indices = train_test_split(np.arange(len(X)), test_size=500, random_state=42, stratify=y)\n",
    "X_train, X_holdout = X[train_indices], X[holdout_indices]\n",
    "y_train, y_holdout = y[train_indices], y[holdout_indices]\n",
    "\n",
    "# Check class distribution\n",
    "print(\"Class distribution in training set:\", np.bincount(y_train.astype(int)))\n",
    "print(\"Class distribution in holdout set:\", np.bincount(y_holdout.astype(int)))\n",
    "\n",
    "# Initialize a simple XGBoost model\n",
    "xgb_model = xgb.XGBClassifier(objective='binary:logistic', use_label_encoder=False, eval_metric='logloss', scale_pos_weight=np.sum(y_train == 0) / np.sum(y_train == 1))\n",
    "\n",
    "# Perform Cross-Validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(xgb_model, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "print(f'Cross-validation scores: {cv_scores}')\n",
    "print(f'Mean cross-validation accuracy: {cv_scores.mean():.5f}')\n",
    "\n",
    "# Train the final model on the entire training set\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the final model on the holdout set\n",
    "y_holdout_pred = xgb_model.predict(X_holdout)\n",
    "accuracy = accuracy_score(y_holdout, y_holdout_pred)\n",
    "precision = precision_score(y_holdout, y_holdout_pred)\n",
    "recall = recall_score(y_holdout, y_holdout_pred)\n",
    "roc_auc = roc_auc_score(y_holdout, y_holdout_pred)\n",
    "\n",
    "print(f'Final Model Accuracy on Holdout Set: {accuracy * 100:.2f}%')\n",
    "print(f'Holdout Set Precision: {precision * 100:.2f}%')\n",
    "print(f'Holdout Set Recall: {recall * 100:.2f}%')\n",
    "print(f'Holdout Set ROC AUC: {roc_auc * 100:.2f}%')\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_holdout, y_holdout_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "\n",
    "# Train the model to inspect feature importance\n",
    "xgb_model = xgb.XGBClassifier(objective='binary:logistic', use_label_encoder=False, eval_metric='logloss', scale_pos_weight=np.sum(y_train == 0) / np.sum(y_train == 1))\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Plot feature importance\n",
    "xgb.plot_importance(xgb_model, max_num_features=20)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect random samples\n",
    "sample_indices = np.random.choice(train_indices, size=5, replace=False)\n",
    "print(data.iloc[sample_indices])\n",
    "print(y_pred.iloc[sample_indices])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "# Train logistic regression\n",
    "logreg = LogisticRegression(class_weight='balanced', max_iter=1000)\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on holdout set\n",
    "y_holdout_pred = logreg.predict(X_holdout)\n",
    "accuracy = accuracy_score(y_holdout, y_holdout_pred)\n",
    "precision = precision_score(y_holdout, y_holdout_pred)\n",
    "recall = recall_score(y_holdout, y_holdout_pred)\n",
    "roc_auc = roc_auc_score(y_holdout, y_holdout_pred)\n",
    "\n",
    "print(f'Logistic Regression Accuracy on Holdout Set: {accuracy * 100:.2f}%')\n",
    "print(f'Logistic Regression Precision: {precision * 100:.2f}%')\n",
    "print(f'Logistic Regression Recall: {recall * 100:.2f}%')\n",
    "print(f'Logistic Regression ROC AUC: {roc_auc * 100:.2f}%')\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_holdout, y_holdout_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Train Random Forest\n",
    "rf = RandomForestClassifier(class_weight='balanced', n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on holdout set\n",
    "y_holdout_pred = rf.predict(X_holdout)\n",
    "accuracy = accuracy_score(y_holdout, y_holdout_pred)\n",
    "precision = precision_score(y_holdout, y_holdout_pred)\n",
    "recall = recall_score(y_holdout, y_holdout_pred)\n",
    "roc_auc = roc_auc_score(y_holdout, y_holdout_pred)\n",
    "\n",
    "print(f'Random Forest Accuracy on Holdout Set: {accuracy * 100:.2f}%')\n",
    "print(f'Random Forest Precision: {precision * 100:.2f}%')\n",
    "print(f'Random Forest Recall: {recall * 100:.2f}%')\n",
    "print(f'Random Forest ROC AUC: {roc_auc * 100:.2f}%')\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_holdout, y_holdout_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train XGBoost on augmented data\n",
    "xgb_model.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Evaluate on holdout set\n",
    "y_holdout_pred = xgb_model.predict(X_holdout)\n",
    "accuracy = accuracy_score(y_holdout, y_holdout_pred)\n",
    "precision = precision_score(y_holdout, y_holdout_pred)\n",
    "recall = recall_score(y_holdout, y_holdout_pred)\n",
    "roc_auc = roc_auc_score(y_holdout, y_holdout_pred)\n",
    "\n",
    "print(f'SMOTE XGBoost Accuracy on Holdout Set: {accuracy * 100:.2f}%')\n",
    "print(f'SMOTE XGBoost Precision: {precision * 100:.2f}%')\n",
    "print(f'SMOTE XGBoost Recall: {recall * 100:.2f}%')\n",
    "print(f'SMOTE XGBoost ROC AUC: {roc_auc * 100:.2f}%')\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_holdout, y_holdout_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "data = pd.read_csv('pseudodata_præoperation.csv')\n",
    "y = np.random.choice([0,1],size = len(data))\n",
    "\n",
    "X = data.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9721362229102167"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_negative = np.sum(y == 0)\n",
    "num_positive = np.sum(y == 1)\n",
    "scale_pos_weight = num_negative / num_positive\n",
    "scale_pos_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [scale_pos_weight*0.25,scale_pos_weight*0.5,scale_pos_weight*0.75,scale_pos_weight,scale_pos_weight*1.75,scale_pos_weight*1.5,scale_pos_weight*2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from xgboost import XGBClassifier\n",
    "from skopt.space import Real, Integer\n",
    "\n",
    "# # Generate synthetic data\n",
    "# X, y = make_classification(n_samples=6000, n_features=20, random_state=42)\n",
    "\n",
    "# Split data into training and hold-out sets\n",
    "X_train, X_holdout, y_train, y_holdout = train_test_split(X, y, test_size=1/6, random_state=42)\n",
    "\n",
    "# Calculate scale_pos_weight based on training data\n",
    "num_negative = np.sum(y_train == 0)\n",
    "num_positive = np.sum(y_train == 1)\n",
    "scale_pos_weight = num_negative / num_positive\n",
    "\n",
    "# Initialize XGBoost classifier\n",
    "model = XGBClassifier()\n",
    "\n",
    "# Define the hyperparameter space\n",
    "param_space = {\n",
    "    'n_estimators': Integer(10, 5000),\n",
    "    'max_depth': Integer(1, 10),\n",
    "    'learning_rate': Real(0.001, 0.01, prior='log-uniform'),\n",
    "    'subsample': Real(0.6, 1.0),\n",
    "    'colsample_bytree': Real(0.6, 1.0),\n",
    "    'gamma': Real(0, 5),\n",
    "    'scale_pos_weight': Real(scale_pos_weight*0.25, scale_pos_weight*2)\n",
    "}\n",
    "\n",
    "# Define the scoring metrics\n",
    "scoring = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
    "\n",
    "# Initialize BayesSearchCV\n",
    "opt = BayesSearchCV(\n",
    "    estimator=model,\n",
    "    search_spaces=param_space,\n",
    "    scoring=scoring,\n",
    "    n_iter=50,  # Number of iterations for Bayesian optimization\n",
    "    cv=5,  # Number of cross-validation folds\n",
    "    n_jobs=-1,\n",
    "    return_train_score=True,\n",
    "    refit='roc_auc',  # Refit the best model on the entire training set using ROC AUC\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Perform Bayesian optimization\n",
    "opt.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on hold-out set\n",
    "y_pred_holdout = opt.predict(X_holdout)\n",
    "print(\"Hold-Out Set Metrics:\")\n",
    "for metric in scoring:\n",
    "    if metric in ['accuracy', 'precision', 'recall', 'f1']:\n",
    "        score = globals()[f\"{metric}_score\"](y_holdout, y_pred_holdout)\n",
    "    elif metric == 'roc_auc':\n",
    "        score = roc_auc_score(y_holdout, opt.predict_proba(X_holdout)[:, 1])\n",
    "    print(f\"{metric.capitalize()}: {score}\")\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best parameters:\", opt.best_params_)\n",
    "print(\"Best ROC AUC:\", opt.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Real(low=0.25, high=2.0, prior='uniform', transform='identity')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Real(scale_pos_weight*0.25, scale_pos_weight*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from skopt.space import Real, Integer\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "# Initialize the classifier with learning rate\n",
    "model = XGBClassifier(learning_rate=0.1, max_depth=6, n_estimators=100)\n",
    "\n",
    "scoring = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
    "\n",
    "# Define the hyperparameter space\n",
    "param_space = {\n",
    "    'n_estimators': Integer(10, 100),\n",
    "    'max_depth': Integer(1, 20),\n",
    "    'learning_rate': Real(0.001, 0.01, prior='log-uniform'),\n",
    "    'min_samples_split': Integer(2, 20),\n",
    "    'min_samples_leaf': Integer(1, 20)\n",
    "}\n",
    "\n",
    "# Define the scoring metrics\n",
    "scoring = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
    "\n",
    "# Initialize BayesSearchCV\n",
    "opt = BayesSearchCV(\n",
    "    estimator=model,\n",
    "    search_spaces=param_space,\n",
    "    scoring='roc_auc',  # This is the primary scoring metric for optimization\n",
    "    n_iter=50,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    return_train_score=True,\n",
    "    refit='roc_auc'\n",
    ")\n",
    "\n",
    "# Perform the optimization\n",
    "opt.fit(X, y)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best parameters:\", opt.best_params_)\n",
    "print(\"Best ROC AUC:\", opt.best_score_)\n",
    "\n",
    "# Optionally, evaluate other metrics using cross_validate\n",
    "best_model = opt.best_estimator_\n",
    "additional_scores = ['accuracy', 'precision', 'recall', 'f1']\n",
    "cross_val_scores = cross_validate(best_model, X, y, scoring=additional_scores, cv=5, n_jobs=-1, return_train_score=True)\n",
    "\n",
    "\n",
    "scores = cross_validate(model, X, y, scoring=scoring, cv=5, n_jobs=-1, return_train_score=True)\n",
    "\n",
    "for metric in scoring:\n",
    "    print(f\"{metric.capitalize()}: {scores['test_' + metric].mean()}\")\n",
    "\n",
    "for metric in scoring:\n",
    "    print(f\"Train {metric.capitalize()}: {scores['train_' + metric].mean()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate xgboost algorithm for classification\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "# define dataset\n",
    "# data = pd.read_csv('x_matricer/x_matrix_pre_4729.csv', compression='gzip').sort_values(by='IDno',ignore_index=True).drop(columns='IDno')\n",
    "# y_pred = pd.read_csv('y_pred_4729.csv').sort_values(by='IDno',ignore_index=True).drop(columns='IDno')\n",
    "\n",
    "data = pd.read_csv('pseudodata_præoperationer.csv', compression='gzip').sort_values(by='IDno',ignore_index=True).drop(columns='IDno')\n",
    "y = np.random.choice([0,1],size = len(data))\n",
    "\n",
    "# Convert to numpy array and generate synthetic labels for demonstration\n",
    "X = data.to_numpy()\n",
    "# y = y_pred.to_numpy()\n",
    "# define the model\n",
    "model = XGBClassifier()\n",
    "# evaluate the model\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(model, X, y, scoring = 'accuracy', cv=cv, n_jobs=-1)\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "model = XGBRegressor()\n",
    "# evaluate the model\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(model, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1, error_score='raise')\n",
    "# report performance\n",
    "print('MAE: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore xgboost number of trees effect on performance\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "from matplotlib import pyplot\n",
    "\n",
    "\n",
    "\n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "\tmodels = dict()\n",
    "\ttrees = [10, 50, 100, 500, 1000, 5000]\n",
    "\tfor n in trees:\n",
    "\t\tmodels[str(n)] = XGBClassifier(n_estimators=n)\n",
    "\treturn models\n",
    "\n",
    "# evaluate a give model using cross-validation\n",
    "def evaluate_model(model):\n",
    "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\tscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\treturn scores\n",
    "\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "\tscores = evaluate_model(model)\n",
    "\tresults.append(scores)\n",
    "\tnames.append(name)\n",
    "\tprint('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
    "# plot model performance for comparison\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore xgboost tree depth effect on performance\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "from matplotlib import pyplot\n",
    "\n",
    "\n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "\tmodels = dict()\n",
    "\tfor i in range(1,11):\n",
    "\t\tmodels[str(i)] = XGBClassifier(max_depth=i)\n",
    "\treturn models\n",
    "\n",
    "# evaluate a give model using cross-validation\n",
    "def evaluate_model(model):\n",
    "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\tscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\treturn scores\n",
    "\n",
    "\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "\tscores = evaluate_model(model)\n",
    "\tresults.append(scores)\n",
    "\tnames.append(name)\n",
    "\tprint('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
    "# plot model performance for comparison\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore xgboost learning rate effect on performance\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# get the dataset\n",
    "def get_dataset():\n",
    "\tX, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=7)\n",
    "\treturn X, y\n",
    "\n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "\tmodels = dict()\n",
    "\trates = [0.00001, 0.001, 0.01, 0.1, 1.0]\n",
    "\tfor i in range(1,11):\n",
    "\t\tfor r in rates:\n",
    "\t\t\tkey = '%.4f' % r\n",
    "\t\t\tmodels[(str(i),key)] = XGBClassifier(max_depth=i,eta=r)\n",
    "\treturn models\n",
    "\n",
    "# evaluate a give model using cross-validation\n",
    "def evaluate_model(model):\n",
    "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\tscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\treturn scores\n",
    "\n",
    "\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "\tscores = evaluate_model(model)\n",
    "\tresults.append(scores)\n",
    "\tnames.append(name)\n",
    "\tprint('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
    "# plot model performance for comparison\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore xgboost subsample ratio effect on performance\n",
    "from numpy import arange\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# get the dataset\n",
    "def get_dataset():\n",
    "\tX, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=7)\n",
    "\treturn X, y\n",
    "\n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "\tmodels = dict()\n",
    "\tfor i in arange(0.1, 1.1, 0.1):\n",
    "\t\tkey = '%.1f' % i\n",
    "\t\tmodels[key] = XGBClassifier(subsample=i)\n",
    "\treturn models\n",
    "\n",
    "# evaluate a give model using cross-validation\n",
    "def evaluate_model(model):\n",
    "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\tscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\treturn scores\n",
    "\n",
    "\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "\tprint(name)\n",
    "\tscores = evaluate_model(model)\n",
    "\tresults.append(scores)\n",
    "\tnames.append(name)\n",
    "\tprint('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
    "# plot model performance for comparison\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n",
      "Best parameters found: {'learning_rate': 0.3, 'max_depth': 5, 'n_estimators': 1000, 'scale_pos_weight': 1327}\n",
      "Best cross-validation accuracy: 0.50113\n",
      "Final Model Accuracy on Holdout Set: 50.47%\n",
      "Holdout Set Precision: 48.66%\n",
      "Holdout Set Recall: 79.37%\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "\n",
    "# Load and preprocess data\n",
    "# data = pd.read_csv('x_matricer/x_matrix_pre_4729.csv', compression='gzip').sort_values(by='IDno', ignore_index=True).drop(columns='IDno')\n",
    "# y_pred = pd.read_csv('y_pred_4729.csv').sort_values(by='IDno', ignore_index=True).drop(columns='IDno')\n",
    "# X = data.to_numpy()\n",
    "# y = y_pred.to_numpy().flatten()\n",
    "\n",
    "# # Standardize the data\n",
    "# X = StandardScaler().fit_transform(X)\n",
    "\n",
    "data = pd.read_csv('pseudodata_præoperation.csv')\n",
    "y = np.random.choice([0,1],size = len(data))\n",
    "\n",
    "X = data.to_numpy()\n",
    "\n",
    "# Split data into holdout set and remaining set\n",
    "X_train, X_holdout, y_train, y_holdout = train_test_split(X, y, test_size=1/6, random_state=42)\n",
    "\n",
    "# Create a DMatrix for XGBoost\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dholdout = xgb.DMatrix(X_holdout, label=y_holdout)\n",
    "\n",
    "scale_pos_weight = num_negative / num_positive\n",
    "\n",
    "# Define a simple parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.0001, 0.001, 0.01, 0.3],\n",
    "    'n_estimators': [10, 50, 100, 500, 1000, 5000],\n",
    "    'scale_pos_weight': [0.1*num_negative,num_negative,num_negative*1.5,num_negative*2]  # Adjust for class imbalance\n",
    "}\n",
    "\n",
    "# Initialize a XGBoost model\n",
    "xgb_model = xgb.XGBClassifier(objective='binary:logistic', use_label_encoder=False)\n",
    "\n",
    "scoring = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
    "\n",
    "# Perform Grid Search with Cross-Validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, scoring='accuracy', cv=cv, verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters found\n",
    "print(f'Best parameters found: {grid_search.best_params_}')\n",
    "print(f'Best cross-validation accuracy: {grid_search.best_score_:.5f}')\n",
    "\n",
    "# Train the final model with the best parameters\n",
    "best_model = grid_search.best_estimator_\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the final model on the holdout set\n",
    "y_holdout_pred = best_model.predict(X_holdout)\n",
    "accuracy = accuracy_score(y_holdout, y_holdout_pred)\n",
    "precision = precision_score(y_holdout, y_holdout_pred)\n",
    "recall = recall_score(y_holdout, y_holdout_pred)\n",
    "\n",
    "print(f'Final Model Accuracy on Holdout Set: {accuracy * 100:.2f}%')\n",
    "print(f'Holdout Set Precision: {precision * 100:.2f}%')\n",
    "print(f'Holdout Set Recall: {recall * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, confusion_matrix\n",
    "\n",
    "# Split data into holdout set and remaining set\n",
    "train_indices, holdout_indices = train_test_split(np.arange(len(X)), test_size=500, random_state=42, stratify=y)\n",
    "X_train, X_holdout = X[train_indices], X[holdout_indices]\n",
    "y_train, y_holdout = y[train_indices], y[holdout_indices]\n",
    "\n",
    "# Check class distribution\n",
    "print(\"Class distribution in training set:\", np.bincount(y_train.astype(int)))\n",
    "print(\"Class distribution in holdout set:\", np.bincount(y_holdout.astype(int)))\n",
    "\n",
    "# Create a DMatrix for XGBoost\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dholdout = xgb.DMatrix(X_holdout, label=y_holdout)\n",
    "\n",
    "# Define a simple parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.3],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'scale_pos_weight': [np.sum(y_train == 0) / np.sum(y_train == 1)]  # Adjust for class imbalance\n",
    "}\n",
    "\n",
    "# Initialize a XGBoost model\n",
    "xgb_model = xgb.XGBClassifier(objective='binary:logistic', use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "# Perform Grid Search with Cross-Validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, scoring='accuracy', cv=cv, verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters found\n",
    "print(f'Best parameters found: {grid_search.best_params_}')\n",
    "print(f'Best cross-validation accuracy: {grid_search.best_score_:.5f}')\n",
    "\n",
    "# Train the final model with the best parameters\n",
    "best_model = grid_search.best_estimator_\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the final model on the holdout set\n",
    "y_holdout_pred = best_model.predict(X_holdout)\n",
    "accuracy = accuracy_score(y_holdout, y_holdout_pred)\n",
    "precision = precision_score(y_holdout, y_holdout_pred)\n",
    "recall = recall_score(y_holdout, y_holdout_pred)\n",
    "\n",
    "print(f'Final Model Accuracy on Holdout Set: {accuracy * 100:.2f}%')\n",
    "print(f'Holdout Set Precision: {precision * 100:.2f}%')\n",
    "print(f'Holdout Set Recall: {recall * 100:.2f}%')\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_holdout, y_holdout_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, confusion_matrix, roc_auc_score\n",
    "\n",
    "\n",
    "# Split data into holdout set and remaining set\n",
    "train_indices, holdout_indices = train_test_split(np.arange(len(X)), test_size=500, random_state=42, stratify=y)\n",
    "X_train, X_holdout = X[train_indices], X[holdout_indices]\n",
    "y_train, y_holdout = y[train_indices], y[holdout_indices]\n",
    "\n",
    "# Check class distribution\n",
    "print(\"Class distribution in training set:\", np.bincount(y_train.astype(int)))\n",
    "print(\"Class distribution in holdout set:\", np.bincount(y_holdout.astype(int)))\n",
    "\n",
    "# Initialize a simple XGBoost model\n",
    "xgb_model = xgb.XGBClassifier(objective='binary:logistic', use_label_encoder=False, eval_metric='logloss', scale_pos_weight=np.sum(y_train == 0) / np.sum(y_train == 1))\n",
    "\n",
    "# Perform Cross-Validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(xgb_model, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "print(f'Cross-validation scores: {cv_scores}')\n",
    "print(f'Mean cross-validation accuracy: {cv_scores.mean():.5f}')\n",
    "\n",
    "# Train the final model on the entire training set\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the final model on the holdout set\n",
    "y_holdout_pred = xgb_model.predict(X_holdout)\n",
    "accuracy = accuracy_score(y_holdout, y_holdout_pred)\n",
    "precision = precision_score(y_holdout, y_holdout_pred)\n",
    "recall = recall_score(y_holdout, y_holdout_pred)\n",
    "roc_auc = roc_auc_score(y_holdout, y_holdout_pred)\n",
    "\n",
    "print(f'Final Model Accuracy on Holdout Set: {accuracy * 100:.2f}%')\n",
    "print(f'Holdout Set Precision: {precision * 100:.2f}%')\n",
    "print(f'Holdout Set Recall: {recall * 100:.2f}%')\n",
    "print(f'Holdout Set ROC AUC: {roc_auc * 100:.2f}%')\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_holdout, y_holdout_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "\n",
    "# Train the model to inspect feature importance\n",
    "xgb_model = xgb.XGBClassifier(objective='binary:logistic', use_label_encoder=False, eval_metric='logloss', scale_pos_weight=np.sum(y_train == 0) / np.sum(y_train == 1))\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Plot feature importance\n",
    "xgb.plot_importance(xgb_model, max_num_features=20)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect random samples\n",
    "sample_indices = np.random.choice(train_indices, size=5, replace=False)\n",
    "print(data.iloc[sample_indices])\n",
    "print(y_pred.iloc[sample_indices])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "# Train logistic regression\n",
    "logreg = LogisticRegression(class_weight='balanced', max_iter=1000)\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on holdout set\n",
    "y_holdout_pred = logreg.predict(X_holdout)\n",
    "accuracy = accuracy_score(y_holdout, y_holdout_pred)\n",
    "precision = precision_score(y_holdout, y_holdout_pred)\n",
    "recall = recall_score(y_holdout, y_holdout_pred)\n",
    "roc_auc = roc_auc_score(y_holdout, y_holdout_pred)\n",
    "\n",
    "print(f'Logistic Regression Accuracy on Holdout Set: {accuracy * 100:.2f}%')\n",
    "print(f'Logistic Regression Precision: {precision * 100:.2f}%')\n",
    "print(f'Logistic Regression Recall: {recall * 100:.2f}%')\n",
    "print(f'Logistic Regression ROC AUC: {roc_auc * 100:.2f}%')\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_holdout, y_holdout_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Train Random Forest\n",
    "rf = RandomForestClassifier(class_weight='balanced', n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on holdout set\n",
    "y_holdout_pred = rf.predict(X_holdout)\n",
    "accuracy = accuracy_score(y_holdout, y_holdout_pred)\n",
    "precision = precision_score(y_holdout, y_holdout_pred)\n",
    "recall = recall_score(y_holdout, y_holdout_pred)\n",
    "roc_auc = roc_auc_score(y_holdout, y_holdout_pred)\n",
    "\n",
    "print(f'Random Forest Accuracy on Holdout Set: {accuracy * 100:.2f}%')\n",
    "print(f'Random Forest Precision: {precision * 100:.2f}%')\n",
    "print(f'Random Forest Recall: {recall * 100:.2f}%')\n",
    "print(f'Random Forest ROC AUC: {roc_auc * 100:.2f}%')\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_holdout, y_holdout_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train XGBoost on augmented data\n",
    "xgb_model.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Evaluate on holdout set\n",
    "y_holdout_pred = xgb_model.predict(X_holdout)\n",
    "accuracy = accuracy_score(y_holdout, y_holdout_pred)\n",
    "precision = precision_score(y_holdout, y_holdout_pred)\n",
    "recall = recall_score(y_holdout, y_holdout_pred)\n",
    "roc_auc = roc_auc_score(y_holdout, y_holdout_pred)\n",
    "\n",
    "print(f'SMOTE XGBoost Accuracy on Holdout Set: {accuracy * 100:.2f}%')\n",
    "print(f'SMOTE XGBoost Precision: {precision * 100:.2f}%')\n",
    "print(f'SMOTE XGBoost Recall: {recall * 100:.2f}%')\n",
    "print(f'SMOTE XGBoost ROC AUC: {roc_auc * 100:.2f}%')\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_holdout, y_holdout_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
